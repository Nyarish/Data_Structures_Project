{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Recently Used Cache\n",
    "We have briefly discussed caching as part of a practice problem while studying hash maps.\n",
    "\n",
    "The lookup operation (i.e., `get()`) and `put()` / `set()` is supposed to be fast for a cache memory.\n",
    "\n",
    "While doing the `get()` operation, if the entry is found in the cache, it is known as a `cache hit`. If, however, the entry is not found, it is known as a `cache miss`.\n",
    "\n",
    "When designing a cache, we also place an upper bound on the size of the cache. If the cache is full and we want to add a new entry to the cache, we use some criteria to remove an element. After removing an element, we use the `put()` operation to insert the new element. The remove operation should also be fast.\n",
    "\n",
    "For our first problem, the goal will be to design a data structure known as a Least Recently Used (LRU) cache. An LRU cache is a type of cache in which we remove the least recently used entry when the cache memory reaches its limit. For the current problem, consider both get and set operations as an use operation.\n",
    "\n",
    "Your job is to use an appropriate data structure(s) to implement the cache.\n",
    "\n",
    "In case of a `cache hit`, your `get()` operation should return the appropriate value.\n",
    "In case of a `cache mis`s, your `get()` should return -1.\n",
    "While putting an element in the cache, your `put()` / `set()` operation must insert the element. If the cache is full, you must write code that removes the least recently used entry first and then insert the element.\n",
    "All operations must take O(1) time.\n",
    "\n",
    "For the current problem, you can consider the size of cache = 5.\n",
    "\n",
    "Here is some boiler plate code and some example test cases to get you started on this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRU_Cache(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        # Initialize class variables\n",
    "        self.size_of_cache = [None for _ in range(capacity)]\n",
    "        self.element_dict = dict()\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def get(self, key):\n",
    "        # Retrieve item from provided key. Return -1 if nonexistent. \n",
    "        pass\n",
    "\n",
    "    def set(self, key, value):\n",
    "        # Set the value if the key is not present in the cache. If the cache is at capacity remove the oldest item. \n",
    "        self.element_dict[key] = value\n",
    "        pass\n",
    "\n",
    "our_cache = LRU_Cache(5)\n",
    "\n",
    "our_cache.set(1, 1);\n",
    "our_cache.set(2, 2);\n",
    "our_cache.set(3, 3);\n",
    "our_cache.set(4, 4);\n",
    "\n",
    "\n",
    "our_cache.get(1)       # returns 1\n",
    "our_cache.get(2)       # returns 2\n",
    "our_cache.get(9)      # returns -1 because 9 is not present in the cache\n",
    "\n",
    "our_cache.set(5, 5) \n",
    "our_cache.set(6, 6)\n",
    "\n",
    "our_cache.get(3)      # returns -1 because the cache reached it's capacity and 3 was the least recently used entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleNode():\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "        self.prev = None\n",
    "        \n",
    "class DoublyLinkedList:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "        self.size = 0\n",
    "    \n",
    "    def append(self, value):\n",
    "        if self.head is None:\n",
    "            self.head = DoubleNode(value)\n",
    "            self.tail = self.head\n",
    "            return\n",
    "            \n",
    "        self.tail.next = DoubleNode(value)\n",
    "        self.tail.next.previous = self.tail\n",
    "        self.tail = self.tail.next\n",
    "        return\n",
    "    def print_linked_list(self):\n",
    "        output = list()\n",
    "        current_node = self.head\n",
    "        \n",
    "        while current_node is not None:\n",
    "            output.append(current_node.value)\n",
    "            current_node = current_node.next \n",
    "            \n",
    "        print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRU_Cache(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        # Initialize class variables\n",
    "        self.cache_array = [None for _ in range(capacity)]\n",
    "        self.capacity = capacity\n",
    "        self.key_list = DoublyLinkedList()\n",
    "        self.num_entries = 0\n",
    "\n",
    "\n",
    "    def get(self, key):\n",
    "        # Retrieve item from provided key. Return -1 if nonexistent. \n",
    "        key = key -1\n",
    "        if key > self.num_entries:\n",
    "            return -1\n",
    "        elif self.cache_array[key] is not None:\n",
    "            new_head = self.key_list.head\n",
    "            self.key_list.head = self.key_list.head.next\n",
    "            self.key_list.tail.next = new_head\n",
    "            self.key_list.tail = self.key_list.tail.next\n",
    "            return self.cache_array[key]\n",
    "        else:\n",
    "            return -1\n",
    "            \n",
    "\n",
    "    def set(self, key, value):\n",
    "        # Set the value if the key is not present in the cache. If the cache is at capacity remove the oldest item. \n",
    "        key = key -1\n",
    "        if key >= self.capacity:\n",
    "            key = key % self.capacity \n",
    "        if self.cache_array[key] is None:\n",
    "            self.cache_array[key] = value\n",
    "            self.num_entries += 1\n",
    "            \n",
    "            if self.key_list is None:\n",
    "                self.key_list.head = DoubleNode(key)\n",
    "                self.key_list.tail = self.key_list.head\n",
    "            else:\n",
    "                self.key_list.append(key)\n",
    "        else:\n",
    "            if self.num_entries == self.capacity:\n",
    "                key_to_remove = self.key_list.head.value\n",
    "                self.cache_array[key_to_remove] = None\n",
    "                \n",
    "                self.num_entries -= 1\n",
    "                \n",
    "            else:\n",
    "                print(\"That Key is filled\")\n",
    "                \n",
    "        print(\"Current Fill level is now at {}\".format(self.num_entries))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Fill level is now at 1\n",
      "This is the current cache_array: [1, None, None, None, None]\n",
      "[0]\n",
      "Current Fill level is now at 2\n",
      "This is the current cache_array: [1, 2, None, None, None]\n",
      "[0, 1]\n",
      "Current Fill level is now at 3\n",
      "This is the current cache_array: [1, 2, 3, None, None]\n",
      "[0, 1, 2]\n",
      "Current Fill level is now at 4\n",
      "This is the current cache_array: [1, 2, 3, 4, None]\n",
      "[0, 1, 2, 3]\n",
      "1\n",
      "2\n",
      "-1\n",
      "Current Fill level is now at 5\n",
      "[1, 2, 3, 4, 5]\n",
      "Current Fill level is now at 4\n",
      "[1, 2, None, 4, 5]\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "our_cache = LRU_Cache(5)\n",
    "\n",
    "our_cache.set(1, 1);\n",
    "print(\"This is the current cache_array: {}\".format(our_cache.cache_array))\n",
    "our_cache.key_list.print_linked_list()\n",
    "\n",
    "our_cache.set(2, 2);\n",
    "print(\"This is the current cache_array: {}\".format(our_cache.cache_array))\n",
    "our_cache.key_list.print_linked_list()\n",
    "\n",
    "our_cache.set(3, 3);\n",
    "print(\"This is the current cache_array: {}\".format(our_cache.cache_array))\n",
    "our_cache.key_list.print_linked_list()\n",
    "\n",
    "our_cache.set(4, 4);\n",
    "print(\"This is the current cache_array: {}\".format(our_cache.cache_array))\n",
    "our_cache.key_list.print_linked_list()\n",
    "\n",
    "\n",
    "\n",
    "print(our_cache.get(1))      # returns 1\n",
    "print(our_cache.get(2))     # returns 2\n",
    "print(our_cache.get(9))     # returns -1 because 9 is not present in the cache\n",
    "\n",
    "\n",
    "our_cache.set(5, 5);\n",
    "print(our_cache.cache_array)\n",
    "\n",
    "our_cache.set(6, 6);\n",
    "print(our_cache.cache_array)\n",
    "\n",
    "print(our_cache.get(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
